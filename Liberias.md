# ğŸ“Š ibrerÃ­as Python para Data Science

> **VersiÃ³n:** 1.0| **Fecha:** Septiembre 2025 | **Autor:** Paula Sandoval
> **DescripciÃ³n:** Resumen completo de las 10 librerÃ­as mÃ¡s importantes para Data Science en Python.
---
### ğŸ† **Mejores 3 liberias**
1. **Pandas** ğŸ¼ - El estÃ¡ndar universal
2. **Polars** âš¡ - El futuro del rendimiento  
3. **DuckDB** ğŸ¦† - La revoluciÃ³n de SQL analÃ­tico

### ğŸ’¡ **Tendencias 2025**
- Polars y DuckDB lideran en velocidad
- RAPIDS hace accesible la computaciÃ³n GPU
- **Backend Unification:** Ibis permite cÃ³digo portable
- **Domain Specialization:** Herramientas especÃ­ficas para cada necesidad

---

### 1. ğŸš€ **Dask - ComputaciÃ³n Paralela y Distribuida**

#### âœ¨ **CaracterÃ­sticas**
- **ğŸ“ˆ Escalabilidad AutomÃ¡tica:** De laptop a cluster sin modificaciones
- **ğŸ”„ API IdÃ©ntica:** `import dask.dataframe as dd` â†’ todo igual que pandas
- **ğŸ§  Lazy Evaluation:** Optimiza antes de ejecutar
- **ğŸ”— Ecosistema:** Integra con NumPy, Pandas, Scikit-Learn

#### ğŸ’» **CÃ³digo de Ejemplo**
```python
import dask.dataframe as dd

# Leer archivo de 10GB como si fuera pequeÃ±o
df = dd.read_csv('massive_data.csv')

# Operaciones familiares
result = (df
    .groupby('category')
    .sales.mean()
    .compute()  # Solo aquÃ­ se ejecuta
)

# ParalelizaciÃ³n automÃ¡tica en 8 cores
df.to_parquet('output/', engine='pyarrow')
```

#### ğŸ“Š **Casos de Uso Perfectos**
- âœ… Datasets > 1GB que no caben en memoria
- âœ… Migrar cÃ³digo pandas existente a big data
- âœ… Procesamiento en mÃºltiples cores/mÃ¡quinas
- âœ… AnÃ¡lisis de series temporales grandes

#### ğŸ”— **Enlaces Esenciales**
- ğŸŒ **Web:** https://www.dask.org/
- ğŸ“– **Docs:** https://docs.dask.org/
- ğŸ“ **Tutorial:** https://tutorial.dask.org/
---

### 2. âš¡ **Polars - DataFrame UltrarrÃ¡pido**

#### âœ¨ **CaracterÃ­sticas**
- **ğŸ¦€ Backend Rust:** Velocidad extrema sin sacrificar funcionalidad
- **ğŸ§  Query Optimizer:** Como tener un DBA personal
- **ğŸ’¾ Memoria Eficiente:** Maneja datasets 10x mÃ¡s grandes
- **ğŸ“ API Moderna:** Sintaxis mÃ¡s expresiva que pandas

#### ğŸ’» **CÃ³digo de ejemplo**
```python
import polars as pl

# Lazy evaluation con optimizaciÃ³n automÃ¡tica
result = (
    pl.scan_csv("sales_2023.csv")
    .filter(pl.col("amount") > 1000)
    .group_by(["region", "product"])
    .agg([
        pl.col("amount").sum().alias("total_sales"),
        pl.col("quantity").mean().alias("avg_quantity"),
        pl.count().alias("transactions")
    ])
    .sort("total_sales", descending=True)
    .collect()  # Query optimizada se ejecuta aquÃ­
)

# Expresiones complejas son simples
df_enhanced = df.with_columns([
    # Crear mÃºltiples columnas en una pasada
    pl.when(pl.col("amount") > pl.col("amount").quantile(0.9))
      .then(pl.lit("Premium"))
      .when(pl.col("amount") > pl.col("amount").quantile(0.7))
      .then(pl.lit("Standard"))
      .otherwise(pl.lit("Basic"))
      .alias("customer_tier"),
      
    # Operaciones de ventana eficientes
    pl.col("amount").sum().over("region").alias("region_total")
])
```

#### ğŸ“Š **CuÃ¡ndo Usar Polars**
- âœ… Nuevos proyectos que priorizan velocidad
- âœ… ETL pesado con millones de filas
- âœ… AnÃ¡lisis financiero de alta frecuencia
- âœ… Cuando pandas se vuelve lento

#### ğŸ¯ **MigraciÃ³n desde Pandas**
```python
# PANDAS (lento)
df.groupby('category')['sales'].mean().reset_index()

# POLARS (30x mÃ¡s rÃ¡pido)
df.group_by('category').agg(pl.col('sales').mean())
```

#### ğŸ”— **Enlaces Esenciales**
- ğŸŒ **Web:** https://pola.rs/
- ğŸ“– **Docs:** https://docs.pola.rs/
- ğŸ’» **GitHub:** https://github.com/pola-rs/polars
- ğŸ† **Benchmarks:** https://pola.rs/posts/benchmarks/

---

### 3. ğŸï¸ **RAPIDS - AceleraciÃ³n GPU para Data Science**

#### âœ¨ **CaracterÃ­sticas**
- **ğŸ® GPU NVIDIA:** Aprovecha miles de cores en paralelo
- **ğŸ”„ API Compatible:** Drop-in replacement para pandas/sklearn
- **ğŸ“Š Suite Completa:** DataFrame (cuDF) + ML (cuML) + Grafos (cuGraph)
- **ğŸ’° ROI Inmediato:** Una GPU = 10-100 CPUs en analytics

#### ğŸ’» **CÃ³digo de ejemplo**
```python
import cudf  # GPU DataFrame
import cuml  # GPU Machine Learning
import cugraph  # GPU Graph Analytics

# DataFrame en GPU (sintaxis idÃ©ntica a pandas)
df = cudf.read_csv('large_dataset.csv')
gpu_result = df.groupby('category').sales.mean()

# Machine Learning 100x mÃ¡s rÃ¡pido
from cuml.cluster import KMeans
from cuml.ensemble import RandomForestClassifier

# Clustering en millones de puntos
kmeans_gpu = KMeans(n_clusters=50)
clusters = kmeans_gpu.fit_predict(df[['lat', 'lon', 'amount']])

# Random Forest en GPU
rf_gpu = RandomForestClassifier(n_estimators=100)
rf_gpu.fit(X_train, y_train)
predictions = rf_gpu.predict(X_test)

# AnÃ¡lisis de grafos masivos
G = cugraph.Graph()
G.from_cudf_edgelist(edges_df, source='src', destination='dst')
pagerank_scores = cugraph.pagerank(G)
```

#### ğŸ¯ **Hardware Requirements**
- **MÃ­nimo:** NVIDIA GTX 1060 (6GB VRAM)
- **Recomendado:** RTX 3080+ (12GB+ VRAM)
- **Empresarial:** A100/V100 (40GB+ VRAM)

#### ğŸ”— **Enlaces Esenciales**
- ğŸŒ **Web:** https://rapids.ai/
- ğŸ“– **Docs:** https://docs.rapids.ai/
- ğŸš€ **Quickstart:** https://rapids.ai/start.html
- ğŸ’» **GitHub:** https://github.com/rapidsai/

---

### 4. ğŸ—ºï¸ **GeoPandas - AnÃ¡lisis de Datos Geoespaciales**

#### âœ¨ **CaracterÃ­sticas **
- **ğŸ¼ ExtensiÃ³n Natural:** Todas las funciones de pandas + geometrÃ­as
- **ğŸ“ Operaciones Espaciales:** Buffer, intersect, union, dissolve
- **ğŸ—ºï¸ Coordenadas:** Manejo automÃ¡tico de sistemas de referencia
- **ğŸ“Š VisualizaciÃ³n:** Mapas integrados con matplotlib

#### ğŸ’» **CÃ³digo de ejemplo**
```python
import geopandas as gpd
import matplotlib.pyplot as plt
from shapely.geometry import Point

# Leer datos geoespaciales
world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))
cities = gpd.read_file('world_cities.shp')

# Crear geometrÃ­as desde coordenadas
df = pd.DataFrame({
    'city': ['Madrid', 'Barcelona', 'Valencia'],
    'lat': [40.4168, 41.3851, 39.4699],
    'lon': [-3.7038, 2.1734, -0.3763]
})
gdf = gpd.GeoDataFrame(df, 
    geometry=gpd.points_from_xy(df.lon, df.lat),
    crs='EPSG:4326'
)

# Operaciones geoespaciales
# Buffer de 100km alrededor de cada ciudad
city_buffers = gdf.to_crs('EPSG:3857').buffer(100000)

# Encontrar paÃ­ses que intersectan con los buffers
spain = world[world.name == 'Spain']
intersections = gpd.overlay(city_buffers, spain, how='intersection')

# AnÃ¡lisis de proximidad
nearest_city = cities.sindex.nearest(gdf.geometry)

# VisualizaciÃ³n avanzada
fig, ax = plt.subplots(figsize=(15, 10))
world.plot(ax=ax, color='lightgray', edgecolor='white')
gdf.plot(ax=ax, color='red', markersize=100, alpha=0.7)
city_buffers.plot(ax=ax, alpha=0.3, color='blue')
plt.title('AnÃ¡lisis Geoespacial con GeoPandas')
```

#### ğŸ“Š **Ejemplos empresariales**
- ğŸšš **LogÃ­stica:** OptimizaciÃ³n de rutas y zonas de entrega
- ğŸ™ï¸ **Smart Cities:** PlanificaciÃ³n urbana basada en datos
- ğŸŒ **Medio Ambiente:** Monitoreo de deforestaciÃ³n y cambio climÃ¡tico

#### ğŸ”— **Enlaces Esenciales**
- ğŸŒ **Web:** https://geopandas.org/
- ğŸ“– **Docs:** https://geopandas.org/en/stable/
- ğŸŒ **Ecosistema:** https://geopandas.org/en/latest/community/ecosystem.html
- ğŸ“ **Gallery:** https://geopandas.org/en/stable/gallery/index.html

---

### 5. ğŸ•¸ï¸ **NetworkX - AnÃ¡lisis de Redes y Grafos**

#### âœ¨ **CaracterÃ­sticas **
- **ğŸ§  Algoritmos Avanzados:** 200+ algoritmos de grafos implementados
- **ğŸ“Š MÃ©tricas Completas:** Centralidad, clustering, modularidad
- **ğŸ¨ VisualizaciÃ³n:** IntegraciÃ³n nativa con matplotlib
- **âš¡ Escalabilidad:** Compatible con RAPIDS para GPU

#### ğŸ’» **CÃ³digo de ejemplo**
```python
import networkx as nx
import matplotlib.pyplot as plt
import pandas as pd

# Crear red desde datos
edges = pd.DataFrame([
    ('Alice', 'Bob', 0.8),
    ('Bob', 'Charlie', 0.6),
    ('Charlie', 'Diana', 0.9),
    ('Diana', 'Alice', 0.7),
    ('Alice', 'Eve', 0.5)
], columns=['source', 'target', 'weight'])

G = nx.from_pandas_edgelist(edges, edge_attr='weight')

# AnÃ¡lisis de centralidad
centrality_metrics = {
    'betweenness': nx.betweenness_centrality(G),
    'closeness': nx.closeness_centrality(G), 
    'eigenvector': nx.eigenvector_centrality(G),
    'pagerank': nx.pagerank(G)
}

# DetecciÃ³n de comunidades
communities = list(nx.community.greedy_modularity_communities(G))
print(f"Encontradas {len(communities)} comunidades")

# AnÃ¡lisis de conectividad
print(f"Densidad de la red: {nx.density(G):.3f}")
print(f"Coeficiente de clustering: {nx.average_clustering(G):.3f}")

# VisualizaciÃ³n avanzada
pos = nx.spring_layout(G, k=1, iterations=50)
plt.figure(figsize=(12, 8))

# TamaÃ±o de nodos proporcional a centralidad
node_sizes = [centrality_metrics['betweenness'][node] * 3000 for node in G.nodes()]

nx.draw_networkx_nodes(G, pos, node_size=node_sizes, 
                       node_color='lightblue', alpha=0.7)
nx.draw_networkx_labels(G, pos, font_size=12, font_weight='bold')
nx.draw_networkx_edges(G, pos, width=2, alpha=0.5, edge_color='gray')

plt.title("Red Social - AnÃ¡lisis de Centralidad")
plt.axis('off')
plt.show()
```

#### ğŸ“Š **Algoritmos Destacados**
- **ğŸ¯ Centralidad:** Betweenness, Closeness, Eigenvector, PageRank
- **ğŸ‘¥ Comunidades:** Modularity, Louvain, Label Propagation
- **ğŸ›£ï¸ Caminos:** Shortest Path, All Pairs, A* Search
- **ğŸ” Matching:** Maximum Bipartite, Minimum Weight
- **ğŸŒŠ Flujo:** Max Flow, Min Cut, Cost Flow

#### ğŸ¯ **Casos de Uso por Industria**
- **ğŸ“± Redes Sociales:** Influencers, comunidades, propagaciÃ³n viral
- **ğŸ¦ Finanzas:** DetecciÃ³n de fraude, anÃ¡lisis de riesgo sistÃ©mico
- **ğŸ§¬ BioinformÃ¡tica:** Redes de proteÃ­nas, pathways metabÃ³licos
- **ğŸšš Supply Chain:** OptimizaciÃ³n logÃ­stica, vulnerabilidades

#### ğŸ”— **Enlaces Esenciales**
- ğŸŒ **Web:** https://networkx.org/
- ğŸ“– **Docs:** https://networkx.org/documentation/stable/
- ğŸ“ **Tutorial:** https://networkx.org/documentation/stable/tutorial.html
- ğŸ—ºï¸ **Geo Examples:** https://networkx.org/documentation/stable/auto_examples/geospatial/

---

### 6. ğŸ”¢ **Xarray - Arrays Multidimensionales Etiquetados**

#### âœ¨ **CaracterÃ­sticas **
- **ğŸ·ï¸ Dimensiones Nombradas:** AdiÃ³s a confusiÃ³n con ejes
- **ğŸ“… Coordenadas Inteligentes:** Tiempo, latitud, longitud automÃ¡ticos  
- **ğŸš€ Dask Integration:** Datasets de terabytes sin problemas
- **ğŸ’¾ Formatos CientÃ­ficos:** NetCDF, HDF5, Zarr nativos

#### ğŸ’» **CÃ³digo de ejemplo**
```python
import xarray as xr
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# Crear DataArray con dimensiones etiquetadas
temperature = xr.DataArray(
    np.random.randn(365, 50, 100),  # 1 aÃ±o, 50 latitudes, 100 longitudes
    dims=['time', 'lat', 'lon'],
    coords={
        'time': pd.date_range('2023-01-01', periods=365),
        'lat': np.linspace(-90, 90, 50),
        'lon': np.linspace(-180, 180, 100)
    },
    attrs={
        'units': 'degrees_celsius',
        'description': 'Daily temperature anomalies'
    }
)

# Operaciones intuitivas con etiquetas
summer = temperature.sel(time=temperature.time.dt.season == 'JJA')
tropics = temperature.sel(lat=slice(-23.5, 23.5))
madrid_temp = temperature.sel(lat=40.4, lon=-3.7, method='nearest')

# Agregaciones por dimensiÃ³n
monthly_avg = temperature.groupby('time.month').mean()
annual_cycle = temperature.groupby('time.dayofyear').mean()

# Operaciones matemÃ¡ticas preservan metadatos
anomaly = temperature - temperature.mean(dim='time')
normalized = (temperature - temperature.mean()) / temperature.std()

# VisualizaciÃ³n integrada
fig, axes = plt.subplots(2, 2, figsize=(15, 10))

# Mapa promedio anual
temperature.mean(dim='time').plot(ax=axes[0,0], cmap='RdBu_r')
axes[0,0].set_title('Temperatura Promedio Anual')

# Serie temporal en Madrid
madrid_temp.plot(ax=axes[0,1])
axes[0,1].set_title('Serie Temporal - Madrid')

# Ciclo anual promedio
annual_cycle.mean(dim=['lat', 'lon']).plot(ax=axes[1,0])
axes[1,0].set_title('Ciclo Anual Global')

# Diferencia estacional
(summer.mean() - temperature.sel(time=temperature.time.dt.season == 'DJF').mean()).plot(
    ax=axes[1,1], cmap='RdBu_r'
)
axes[1,1].set_title('Diferencia Verano-Invierno')

plt.tight_layout()
plt.show()
```

#### ğŸ“Š **Ventajas vs NumPy/Pandas**
| OperaciÃ³n | NumPy | Pandas | Xarray |
|-----------|--------|---------|---------|
| SelecciÃ³n | `arr[0, :, 5]` | `df.iloc[0, 5]` | `da.sel(time='2023-01', lon=-3.7)` |
| AgregaciÃ³n | `arr.mean(axis=0)` | `df.mean()` | `da.mean(dim='time')` |
| Metadata | âŒ | Limitado | âœ… Completo |
| Broadcasting | Manual | âŒ | AutomÃ¡tico |

#### ğŸ”¬ **Casos de Uso CientÃ­ficos**
- **ğŸŒ¡ï¸ ClimatologÃ­a:** Modelos climÃ¡ticos, reanÃ¡lisis, proyecciones
- **ğŸ›°ï¸ TeledetecciÃ³n:** ImÃ¡genes satelitales multiespectrales
- **ğŸŒŠ OceanografÃ­a:** Temperatura, salinidad, corrientes 4D
- **ğŸ§¬ Bioimagen:** MicroscopÃ­a 4D (x, y, z, tiempo)

#### ğŸ”— **Enlaces Esenciales**
- ğŸŒ **Web:** https://xarray.dev/
- ğŸ“– **Docs:** https://docs.xarray.dev/
- ğŸ“ **Tutorial:** https://tutorial.xarray.dev/
- ğŸ¨ **Gallery:** https://docs.xarray.dev/en/stable/gallery.html

---

### 7. ğŸ¦† **DuckDB - Base de Datos AnalÃ­tica Embebida**

#### âœ¨ **CaracterÃ­sticas **
- **ğŸ“Š OLAP Puro:** 100x mÃ¡s rÃ¡pido que MySQL en agregaciones
- **ğŸ“¦ Zero Setup:** `pip install duckdb` y listo
- **ğŸ“ Consulta Directa:** Parquet, CSV, JSON sin importar
- **ğŸ”„ SQL Moderno:** Window functions, CTEs, arrays

#### ğŸ’» **CÃ³digo de ejemplo**
```python
import duckdb
import pandas as pd

# Crear conexiÃ³n (en memoria)
con = duckdb.connect()

# Consultar archivos directamente (Â¡sin importar!)
result = con.execute("""
    SELECT 
        category,
        DATE_TRUNC('month', date) as month,
        SUM(amount) as monthly_sales,
        COUNT(*) as transactions,
        AVG(amount) as avg_transaction
    FROM 'sales_data.parquet'  -- Consulta directa
    WHERE date >= '2023-01-01'
    GROUP BY category, month
    ORDER BY monthly_sales DESC
""").fetchdf()

# Mezclar SQL con DataFrames
df_customers = pd.read_csv('customers.csv')
con.register('customers', df_customers)  # Registrar DataFrame

sales_analysis = con.execute("""
    WITH customer_stats AS (
        SELECT 
            customer_id,
            SUM(amount) as total_spent,
            COUNT(*) as visit_count,
            AVG(amount) as avg_purchase
        FROM 'sales_data.parquet'
        GROUP BY customer_id
    )
    SELECT 
        c.customer_name,
        c.segment,
        cs.total_spent,
        cs.visit_count,
        cs.avg_purchase,
        -- Ventana deslizante
        AVG(cs.total_spent) OVER (
            PARTITION BY c.segment 
            ORDER BY cs.total_spent 
            ROWS BETWEEN 2 PRECEDING AND 2 FOLLOWING
        ) as segment_avg_nearby
    FROM customers c
    JOIN customer_stats cs ON c.customer_id = cs.customer_id
    WHERE cs.total_spent > 1000
    ORDER BY cs.total_spent DESC
""").fetchdf()

# Arrays y JSON (funciones modernas)
json_analysis = con.execute("""
    SELECT 
        json_extract(metadata, '$.campaign') as campaign,
        json_extract_string(metadata, '$.source') as source,
        array_length(string_split(tags, ',')) as tag_count
    FROM marketing_data
    WHERE json_valid(metadata)
""").fetchdf()

# Performance: comparar con pandas
import time

# DuckDB: AggregaciÃ³n en 50M filas
start = time.time()
duck_result = con.execute("""
    SELECT category, AVG(amount) 
    FROM huge_sales_file.parquet 
    GROUP BY category
""").fetchdf()
duck_time = time.time() - start

print(f"DuckDB: {duck_time:.2f}s")
# TÃ­picamente 5-20x mÃ¡s rÃ¡pido que pandas equivalente
```

#### ğŸ“Š **Performance Benchmarks**
| OperaciÃ³n | Pandas | DuckDB | Speedup |
|-----------|---------|--------|---------|
| GROUP BY (10M filas) | 15.2s | 1.8s | 8.4x |
| JOIN (5M + 2M) | 12.7s | 2.1s | 6.0x |  
| Window Functions | 25.3s | 3.2s | 7.9x |
| Parquet Read | 8.1s | 0.9s | 9.0x |

#### ğŸ¯ **Casos de Uso Ideales**
- âœ… **Prototipado RÃ¡pido:** Analytics locales sin setup
- âœ… **ETL Pesado:** Transformaciones complejas en CSV/Parquet
- âœ… **Reporting:** Dashboards con queries complejas
- âœ… **Data Apps:** Embedded analytics en aplicaciones

#### ğŸ”— **Enlaces Esenciales**
- ğŸŒ **Web:** https://duckdb.org/
- ğŸ“– **Docs:** https://duckdb.org/docs/stable/
- ğŸš€ **Installation:** https://duckdb.org/docs/installation/
- ğŸ“š **Guides:** https://duckdb.org/docs/stable/guides/

---

### 8. ğŸŒ‰ **Ibis - Interfaz Unificada para Backends MÃºltiples**

#### âœ¨ **CaracterÃ­sticas **
- **ğŸ”— Backend Agnostic:** PostgreSQL, BigQuery, Spark, mismo cÃ³digo
- **âš¡ Smart Execution:** DuckDB por defecto para mÃ¡ximo rendimiento
- **ğŸ§  Lazy Evaluation:** Solo ejecuta cuando es necesario
- **ğŸ“Š DataFrame API:** Sintaxis familiar para SQL subyacente

#### ğŸ’» **CÃ³digo de ejemplo**
```python
import ibis
from ibis import _

# MÃºltiples backends con la misma API
backends = {
    'local': ibis.duckdb.connect(),
    'postgres': ibis.postgres.connect('postgresql://user:pass@host/db'),
    'bigquery': ibis.bigquery.connect(project_id='my-project'),
    'snowflake': ibis.snowflake.connect(
        user='user', password='pass', account='account'
    )
}

# FunciÃ³n analÃ­tica reutilizable
def customer_segmentation(con, table_name):
    """SegmentaciÃ³n RFM que funciona en cualquier backend"""
    
    customers = con.table(table_name)
    
    # Calcular mÃ©tricas RFM
    rfm = (
        customers
        .group_by('customer_id')
        .aggregate(
            # Recency: dÃ­as desde Ãºltima compra
            recency=_.purchase_date.max().delta(
                ibis.today(), 'day'
            ),
            # Frequency: nÃºmero de compras
            frequency=_.customer_id.count(),
            # Monetary: total gastado
            monetary=_.amount.sum()
        )
    )
    
    # Crear percentiles para segmentaciÃ³n
    rfm_scored = (
        rfm
        .mutate(
            r_score=_.recency.percent_rank().round(0) + 1,
            f_score=_.frequency.percent_rank().round(0) + 1, 
            m_score=_.monetary.percent_rank().round(0) + 1
        )
        .mutate(
            rfm_score=(_.r_score * 100 + _.f_score * 10 + _.m_score)
        )
    )
    
    # Segmentos de negocio
    return (
        rfm_scored
        .mutate(
            segment=ibis.cases(
                (_.rfm_score >= 544, 'Champions'),
                (_.rfm_score >= 334, 'Loyal Customers'), 
                (_.rfm_score >= 313, 'Potential Loyalists'),
                (_.rfm_score >= 155, 'At Risk'),
                else_='Lost Customers'
            )
        )
        .group_by('segment')
        .aggregate(
            customers=_.customer_id.count(),
            avg_monetary=_.monetary.mean(),
            avg_frequency=_.frequency.mean()
        )
        .order_by(_.customers.desc())
    )

# Ejecutar en diferentes sistemas
for name, backend in backends.items():
    print(f"\n--- AnÃ¡lisis en {name.upper()} ---")
    try:
        result = customer_segmentation(backend, 'sales_data')
        print(result.execute())
    except Exception as e:
        print(f"Error: {e}")

# MigraciÃ³n transparente
def migrate_analysis(source_backend, target_backend, query):
    """Migra anÃ¡lisis entre sistemas sin cambio de cÃ³digo"""
    
    # Ejecutar en sistema origen
    result = query.execute()
    
    # Crear tabla en destino
    target_backend.create_table('migrated_analysis', result)
    
    return "MigraciÃ³n completada"

# Ejemplo: Local â†’ BigQuery
local_analysis = customer_segmentation(backends['local'], 'customers')
migrate_analysis(backends['local'], backends['bigquery'], local_analysis)
```

#### ğŸ¯ **Casos de Uso EstratÃ©gicos**
- **ğŸ”„ Multi-Cloud:** CÃ³digo que funciona en AWS, GCP, Azure
- **ğŸ“ˆ Escalado Gradual:** Empezar local, escalar a cloud sin reescribir  
- **ğŸ¢ MigraciÃ³n:** Cambiar de Postgres a BigQuery sin drama
- **ğŸ§ª Prototipado:** Desarrollar en DuckDB, producir en Snowflake

#### ğŸ“Š **Backends Soportados**
| CategorÃ­a | Backends |
|-----------|----------|
| **SQL Local** | DuckDB, SQLite, PostgreSQL |
| **Cloud** | BigQuery, Snowflake, Redshift |
| **Big Data** | Spark, Impala, Clickhouse |
| **Especializados** | Polars, Pandas, Dask |

#### ğŸ”— **Enlaces Esenciales**  
- ğŸŒ **Web:** https://ibis-project.org/
- ğŸ“– **Backends:**
